# RTD Calibration Analysis Notebooks

This directory contains Jupyter notebooks for analyzing RTD calibration data.

## ï¿½ Quick Navigation

- [Main Notebooks](#-main-notebooks) â€” Which notebook to use
- [Code Structure](#-code-structure) â€” Where to modify parameters
- [Common Modifications](#-common-modifications) â€” Step-by-step examples
- [Output Structure](#-output-structure) â€” Where to find results
- [Configuration](#-configuration) â€” Advanced settings
- [Troubleshooting](#-troubleshooting) â€” Common issues

---

## ï¿½ğŸ““ Main Notebooks

### **SET_BUENO.ipynb** (Recommended workflow)
Set-level analysis: processes multiple calibration runs grouped by `CalibSetNumber`.

**Workflow:**
1. Loads logfile and groups runs by calibration set
2. Calculates temperature offsets and RMS errors
3. Generates repeatability plots with IQR outlier filtering
4. Produces global mean/sigma plots across all sensors
5. Exports summary CSVs with calibration constants

**Outputs:** `outputs/plot_global_means/`, `outputs/plot_global_sigmas/`

---

### **RUN_BUENO.ipynb**
Run-level analysis: inspect individual temperature measurement files.

**Use cases:**
- Visual inspection of temperature time series
- Channel-by-channel offset plots
- Debugging faulty sensor readings

---

### **SET_BUENO_4runs.ipynb** â­ (Actualizado)
AnÃ¡lisis de sets con **exactamente 4 runs NO-BAD** (excluye 'BAD', solo LN2).

**CaracterÃ­sticas:**
- âœ… Excluye runs marcados como `'BAD'` (solo GOOD o vacÃ­o)
- âœ… Filtra por `Liquid Media = LN2`
- âœ… Solo procesa sets con exactamente 4 runs vÃ¡lidos
- âœ… GrÃ¡fico visual destacando sets seleccionados (verde)
- âœ… Estructura moderna similar a ANALYSIS_ALL_SETS_LN2

**Uso:** AnÃ¡lisis de sets con calibraciÃ³n estÃ¡ndar completa (4 runs de calidad).

**Outputs:** `outputs/set_4runs_no_bad/`

---

### **TREE.ipynb**
Exploratory notebook for dataset structure analysis.

---

### **RUN_BUENO-STS.ipynb**
Run analysis with special temperature setpoint handling.

---

### **ANALYSIS_ALL_SETS_LN2.ipynb** â­ (Nuevo)
AnÃ¡lisis exhaustivo de **todos los calibration sets** con filtros completos.

**CaracterÃ­sticas:**
- âœ… Procesa automÃ¡ticamente todos los sets con â‰¥4 runs
- âœ… **Filtra por Liquid Media = LN2** (excluye LAr)
- âœ… Incluye/excluye runs 'BAD' (configurable)
- âœ… AnÃ¡lisis exploratorio con estadÃ­sticas de filtrado
- âœ… GrÃ¡ficos comparativos y exports CSV

**Uso:** Ideal para anÃ¡lisis completos del dataset con control total sobre filtros.

**Outputs:** `outputs/analysis_all_sets_LN2_*/`

---

## ğŸ“‚ Output Structure

```
outputs/
â”œâ”€â”€ plot_global_means/         # Mean offset plots per sensor
â”‚   â”œâ”€â”€ global_mean_offsets_part_*.png
â”‚   â”œâ”€â”€ skipped_runs_due_to_defects.csv
â”‚   â”œâ”€â”€ outliers_filtered_by_iqr.csv  (if outliers detected)
â”‚   â””â”€â”€ offset_repeatability_summary.csv
â”‚
â””â”€â”€ plot_global_sigmas/        # Sigma/repeatability histograms
    â”œâ”€â”€ global_sigma_histogram_round_*.png
    â””â”€â”€ ...
```

### **Generated CSV Files:**

| File | Description |
|------|-------------|
| `skipped_runs_due_to_defects.csv` | Runs excluded due to faulty channels (filter_faulty_channels) |
| `outliers_filtered_by_iqr.csv` | Individual measurements filtered by IQR method (3Ã—IQR bounds) |
| `offset_repeatability_summary.csv` | Statistical summary: mean, std, min, max per sensor |

---

## ğŸ—ï¸ Code Structure

Understanding where to modify parameters for common tasks:

### **Core Modules** (`RTD_Calibration_VGP/src/`)

```
src/
â”œâ”€â”€ run.py              # Individual run processing
â”‚   â”œâ”€â”€ load_temperature_file()    # Temperature data loading
â”‚   â”œâ”€â”€ filter_faulty_channels()   # Channel-level quality control
â”‚   â””â”€â”€ offsets()                  # Offset calculation (tini, tend params)
â”‚
â”œâ”€â”€ set.py              # Multi-run set analysis
â”‚   â”œâ”€â”€ group_runs_by_set()        # Run grouping logic
â”‚   â”œâ”€â”€ calculate_offsets_and_rms() # Offset aggregation
â”‚   â”œâ”€â”€ offset_repeatability()     # Main plotting function
â”‚   â”‚   â†³ Parameters: tini, tend, ref, save_dir
â”‚   â”œâ”€â”€ plot_global_means()        # Sensor mean plots
â”‚   â””â”€â”€ plot_global_sigmas()       # Repeatability histograms
â”‚
â”œâ”€â”€ logfile.py          # LogFile.csv interface
â”‚   â””â”€â”€ Logfile.log_file           # Main DataFrame attribute
â”‚
â””â”€â”€ utils.py            # Utilities (config loading, etc.)
```

### **Key Data Structures**

| Component | Location | Purpose |
|-----------|----------|---------|
| `LogFile.csv` | `RTD_Calibration_VGP/data/` | Run metadata (sensors, dates, selection status) |
| Temperature files | `data/temperature_files/RTD_Calibs/CalSetN_*/` | Raw temperature measurements (.txt) |
| `runs_by_set` | `Set` instance attribute | Dictionary: `{CalibSetNumber: {filename: Run}}` |
| `offsets_data` | `Set` instance attribute | Aggregated offset matrices after `calculate_offsets_and_rms()` |

---

## ï¿½ Common Modifications

### **1. Change Time Window for Offset Calculation**

**Where:** `set.py` â†’ `offset_repeatability()` or notebook cell calling it

**Parameters:**
- `tini=20` (default) â€” Start time for offset window (seconds)
- `tend=40` (default) â€” End time for offset window (seconds)

**Example in notebook:**
```python
s.offset_repeatability(
    tini=30,      # â† Change: start at 30 seconds
    tend=50,      # â† Change: end at 50 seconds
    save_dir='outputs/custom_window',
    write_csv=False,
    write_excel=False
)
```

**Effect:** Only temperature data between 30-50 seconds used for offset calculation.

---

### **2. Change Reference Sensor**

**Where:** `set.py` â†’ `offset_repeatability()`

**Parameter:**
- `ref=2` (default) â€” Use sensor at position 2 as reference (or `'auto'` for dynamic selection)

**Example:**
```python
s.offset_repeatability(
    ref=5,        # â† Change: use sensor 5 as reference
    # or
    ref='auto'    # â† Use dynamic reference (raised sensors logic)
)
```

**Where reference is used:** Set 3 uses dynamic references from `sensors_raised_by_set[3.0] = [6, 12]`

---

### **3. Include/Exclude BAD Runs**

**Where:** Notebook `ANALYSIS_ALL_SETS_LN2.ipynb` â†’ Cell 3 (Configuration)

**Parameter:**
```python
INCLUDE_BAD_RUNS = True   # â† Change to False to exclude
```

**Effect:** Filters rows where `Selection == 'BAD'` before processing.

**Alternative (code level):** `set.py` â†’ `group_runs_by_set()` line 287:
```python
if selection != "BAD":    # â† Change logic here
```

---

### **4. Change Liquid Media Filter**

**Where:** Notebook `ANALYSIS_ALL_SETS_LN2.ipynb` â†’ Cell 3

**Parameter:**
```python
LIQUID_MEDIA_FILTER = 'LN2'   # â† Change to 'LAr' or None
```

**Effect:** Only processes runs with specified liquid media type.

---

### **5. Adjust IQR Outlier Detection Threshold**

**Where:** `set.py` â†’ `offset_repeatability()` line ~598-650

**Current logic:**
```python
iqr = q3 - q1
lower_bound = q1 - 3 * iqr    # â† Multiplier here
upper_bound = q3 + 3 * iqr    # â† Multiplier here
```

**To change:** Modify the multiplier (3 â†’ 2.5 for stricter, 3 â†’ 4 for looser)

**Effect:** More/fewer measurements flagged as outliers in `outliers_filtered_by_iqr.csv`

---

### **6. Change Minimum Runs per Set**

**Where:** Notebook `ANALYSIS_ALL_SETS_LN2.ipynb` â†’ Cell 3

**Parameter:**
```python
MIN_RUNS_PER_SET = 4   # â† Change to 3, 5, etc.
```

**Or in code:** `set.py` â†’ `group_runs_by_set()` line ~287

---

### **7. Modify Faulty Channel Detection**

**Where:** `run.py` â†’ `filter_faulty_channels()` lines ~248-292

**Current thresholds:**
```python
# Temperature range
valid_temp = (temp >= 70) & (temp <= 320)  # â† Kelvin bounds

# NaN threshold
nan_count = df[channel].isna().sum()
if nan_count > 40:  # â† Max allowed NaNs

# Constant reading detection
if df[channel].std() < 1e-6:  # â† Variation threshold
```

**To modify:** Edit these numeric thresholds in the source code.

---

### **8. Add/Remove Sensors from Discarded List**

**Where:** `set.py` â†’ `discarded_sensors` dictionary (lines ~120-140)

**Example:**
```python
self.discarded_sensors = {
    3.0: [8],        # â† Set 3: discard sensor 8 (channel 8)
    4.0: [8, 14],    # â† Set 4: discard sensors 8, 14
    # Add new entries:
    42.0: [5, 12],   # â† Custom: discard sensors 5, 12 in Set 42
}
```

**Effect:** Sensors excluded before statistical calculations and plotting.

---

### **9. Customize Plot Output Directory**

**Where:** Notebook cells or `set.py` function calls

**Parameter:**
```python
s.offset_repeatability(
    save_dir='outputs/my_custom_analysis',  # â† Change path
)
```

**Result location:** Plots saved to `RTD_Calibration_VGP/notebooks/outputs/my_custom_analysis/`

---

### **10. Disable CSV/Excel Export**

**Where:** Notebook cells calling `offset_repeatability()`

**Parameters:**
```python
s.offset_repeatability(
    write_csv=False,    # â† No CSV files
    write_excel=False,  # â† No Excel files
)
```

**Effect:** Only PNG plots generated (reduces clutter and processing time).

---

## ï¿½ğŸ”„ Typical Workflow

1. **Start kernel** and run cell 1 (module reload)
2. **Load data** (cell 2): reads LogFile.csv, groups runs, calculates offsets
3. **Configure parameters** (cell 3): set filters, thresholds, output directories
4. **Generate plots** (cells 4-5): creates mean/sigma visualizations
5. **Inspect outputs**: check `outputs/` directory for plots and CSVs

---

## ğŸ› ï¸ Configuration

- **Config file**: `RTD_Calibration_VGP/config/config.yaml`
- **Per-set metadata**: `discarded_sensors`, `sensors_raised_by_set`, `set_rounds`
- **Logfile**: `RTD_Calibration_VGP/data/LogFile.csv`
- **Temperature files**: `RTD_Calibration_VGP/data/temperature_files/RTD_Calibs/CalSetN_*/`

---

## ğŸ§ª Filtering Logic

### **1. Channel-level filtering** (`filter_faulty_channels()`)
Excludes entire channels with:
- Temperature outside valid range (70-320 K)
- >40 NaN values
- Constant readings (no variation)

### **2. Statistical outlier filtering** (IQR method)
Removes individual measurements outside:
- Lower bound: Q1 - 3Ã—IQR
- Upper bound: Q3 + 3Ã—IQR

Both filtering stages are logged to CSV files in the output directory.

---

## ï¿½ Where to Find Results

### **By Analysis Type:**

| What you want | Location | File pattern |
|---------------|----------|--------------|
| **Offset repeatability plots** | `outputs/analysis_all_sets_LN2_*/repeatability_set_X/` | `offset_repeatability_set_X.png` |
| **Global mean plots** | `outputs/plot_global_means/` | `global_mean_offsets_part_*.png` |
| **Sigma histograms** | `outputs/plot_global_sigmas/` | `global_sigma_histogram_round_*.png` |
| **Outlier log** | Same as plots | `outliers_filtered_by_iqr.csv` |
| **Skipped runs log** | Same as plots | `skipped_runs_due_to_defects.csv` |
| **Statistical summary** | Same as plots | `offset_repeatability_summary.csv` |

### **Quick Find Commands:**

```bash
# Find all Set 3 outputs
find RTD_Calibration_VGP/notebooks/outputs -name "*set_3*"

# List all repeatability plots
find RTD_Calibration_VGP/notebooks/outputs -name "offset_repeatability*.png"

# Count total processed sets
find RTD_Calibration_VGP/notebooks/outputs -type d -name "repeatability_set_*" | wc -l

# Open specific plot (macOS)
open RTD_Calibration_VGP/notebooks/outputs/analysis_all_sets_LN2_with_bad/repeatability_set_3/offset_repeatability_set_3.0.png
```

---

## ğŸ› Troubleshooting

### **Problem: Set X not appearing in outputs**

**Possible causes:**
1. **Fewer than minimum runs** â€” Check `MIN_RUNS_PER_SET` parameter (default 4)
2. **All runs filtered** â€” Check `skipped_runs_due_to_defects.csv` for that set
3. **Individual run failures** â€” Look for `âš ï¸ Warning: Could not compute offsets` in notebook output
4. **Liquid Media mismatch** â€” Verify `Liquid Media` column in LogFile matches filter

**Debug steps:**
```python
# Check how many runs in logfile for Set X
df = lf.log_file.copy()
df = df[df['Liquid Media'] == 'LN2']
df = df[df['CalibSetNumber'] == X]
print(f"Set {X}: {len(df)} runs in logfile")
print(df[['Filename', 'Selection']])
```

---

### **Problem: Module changes not taking effect**

**Solution:** Always run the reload cell **before** re-running analysis:

```python
# Cell: Reload module
import importlib
from RTD_Calibration_VGP.src import set as set_module
importlib.reload(set_module)
from RTD_Calibration_VGP.src.set import Set
```

**Alternative:** Restart kernel (Kernel â†’ Restart & Run All)

---

### **Problem: "No data in requested time window"**

**Cause:** Temperature file has data but not within `tini`-`tend` range

**Solutions:**
1. **Adjust time window:**
   ```python
   s.offset_repeatability(tini=10, tend=60)  # Wider window
   ```

2. **Check actual data range:**
   ```python
   r = Run('problematic_filename', lf.log_file)
   print(f"Time range: {r.temperature_data['Time'].min()} - {r.temperature_data['Time'].max()}")
   ```

3. **Inspect raw file:**
   ```bash
   head -20 RTD_Calibration_VGP/data/temperature_files/RTD_Calibs/CalSetN_X/filename.txt
   ```

---

### **Problem: Sigma values too high (>1000 mK)**

**Cause:** Faulty channels not being filtered properly

**Solution:** Check if `filter_faulty_channels()` is called:

```python
# In notebook cell:
for fname, run in s.runs_by_set[set_num].items():
    faulty = run.filter_faulty_channels()
    if faulty:
        print(f"{fname}: faulty channels {faulty}")
```

**If not filtered:** Make sure `group_runs_by_set()` includes filtering step (line ~315-320 in `set.py`).

---

### **Problem: Too many outliers filtered**

**Cause:** IQR threshold too strict (3Ã—IQR default)

**Solution:** Modify multiplier in `set.py` line ~600:
```python
lower_bound = q1 - 4 * iqr  # Looser (was 3)
upper_bound = q3 + 4 * iqr
```

---

### **Problem: Can't find temperature files**

**Cause:** Hard-coded path in `run.py` doesn't match your system

**Location:** `run.py` â†’ `load_temperature_file()` line ~170:
```python
cernbox_base = Path('/eos/user/j/jcapotor/RTDdata/')
```

**Solution:** Create symlink or modify path:
```bash
# Option 1: Symlink
ln -s /your/actual/path /eos/user/j/jcapotor/RTDdata

# Option 2: Edit source
# Change cernbox_base in run.py to your path
```

---

### **Problem: Plots not updating**

**Causes & solutions:**
1. **Old files cached** â†’ Delete `outputs/` directory and re-run
2. **Wrong output directory** â†’ Check `save_dir` parameter
3. **Image viewer caching** â†’ Close and reopen image

```bash
# Clean and regenerate
rm -rf RTD_Calibration_VGP/notebooks/outputs/analysis_all_sets_LN2_with_bad/
# Then re-run notebook cells
```

---

## ğŸ“ Best Practices

- âœ… **Always reload the module** (cell 1) after editing `src/` code to avoid stale imports
- âœ… **Check CSV logs** to audit which data was filtered out
- âœ… **Use descriptive save_dir names** for different analyses (e.g., `outputs/test_strict_iqr/`)
- âœ… **Keep LogFile.csv backups** before manual edits
- âœ… **Document parameter changes** in notebook markdown cells
- âœ… **Plots are regenerable** â€” feel free to delete `outputs/` and re-run
- âœ… **Version control changes** to `src/` code for reproducibility

---

## ğŸ“š Further Reading

- **Copilot Instructions:** `.github/copilot-instructions.md` â€” Project conventions and patterns
- **Main README:** `../../README.md` â€” Installation and quick start
- **Source Code:** `../src/` â€” Full implementation details
- **Documentation:** `../../docs/` â€” Analysis methodology and references
